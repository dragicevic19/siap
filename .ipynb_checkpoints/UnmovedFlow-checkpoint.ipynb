{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# MAIN LIBRARIES"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3a200da123b40abc"
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "# STANDARD LIBRARIES\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# MISC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "import shap\n",
    "\n",
    "# CLASSIFICATION MODELS\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from mlxtend.classifier import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# REGRESSION MDOELS\n",
    "from mlxtend.regressor import StackingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-10T01:44:05.437078100Z",
     "start_time": "2023-09-10T01:44:05.276727800Z"
    }
   },
   "id": "f66ea69371e31316"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# EDA"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "905670f0d7cb5ff2"
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "from dataprep.eda import create_report, plot, plot_correlation, plot_missing , plot_diff\n",
    "def interactive_eda(df):\n",
    "    # Create Dataprep EDA report\n",
    "    report = create_report(df)\n",
    "\n",
    "    # Show the report\n",
    "    report.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-10T01:44:05.573841100Z",
     "start_time": "2023-09-10T01:44:05.286051600Z"
    }
   },
   "id": "b3c4b6b0b77069aa"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# BINARYFLOW"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c0ab9a20e54eea8d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Define your custom model and parameter dictionaries Example\n",
    "#custom_model_dict = {'rf': RandomForestClassifier(random_state=42), \n",
    "#                     'custom_model': MyCustomClassifier()\n",
    "#                     }\n",
    "\n",
    "#custom_params_dict = {'rf': {'n_estimators': [100, 150]}, \n",
    "#                      'custom_model': {'some_param': [1, 2, 3]}\n",
    "#                      }\n",
    "\n",
    "def BinaryFlow(X_train, X_test, y_train, y_test, models=['xgb', 'lgbm', 'rf', 'gbm', 'svc'], custom_model_dict=None, custom_params_dict=None):\n",
    "    # Always fit and evaluate basic models: Logistic Regression and Naive Bayes\n",
    "    lr_model = LogisticRegression(random_state=42)\n",
    "    lr_model.fit(X_train, y_train)\n",
    "\n",
    "    nb_model = GaussianNB()\n",
    "    nb_model.fit(X_train, y_train)\n",
    "\n",
    "    evaluate_binary_model(lr_model, 'LOGISTIC REGRESSION CLASSIFIER', X_train, X_test, y_train, y_test)\n",
    "    evaluate_binary_model(nb_model, 'NAIVE BAYES CLASSIFIER', X_train, X_test, y_train, y_test)\n",
    "\n",
    "    # Default model and parameter dictionaries\n",
    "    model_dict = {\n",
    "        'xgb': XGBClassifier(random_state=42),\n",
    "        'lgbm': LGBMClassifier(random_state=42),\n",
    "        'rf': RandomForestClassifier(random_state=42),\n",
    "        'gbm': GradientBoostingClassifier(random_state=42),\n",
    "        'svc': SVC(random_state=42, probability=True)\n",
    "    }\n",
    "\n",
    "    params_dict = {\n",
    "        'xgb': {'n_estimators': [100, 150, 300], 'subsample': [None, 0.3, 0.5, 0.8, 0.9], 'colsample_bytree': [0.3, 0.5, 0.8, 1.0]},\n",
    "        'lgbm': {'n_estimators': [100, 150, 300], 'subsample': [None, 0.3, 0.5, 0.8, 0.9], 'colsample_bytree': [0.3, 0.5, 0.8, 1.0]},\n",
    "        'rf': {'n_estimators': [100, 150, 300], 'min_samples_split': [2, 3, 4], 'min_samples_leaf': [1, 2, 3]},\n",
    "        'gbm': {'n_estimators': [100, 150, 300], 'min_samples_split': [2, 3, 4], 'min_samples_leaf': [1, 2, 3]},\n",
    "        'svc': {'C': [0.1, 1, 10], 'kernel': ['rbf', 'poly', 'sigmoid']}\n",
    "    }\n",
    "\n",
    "    # Use custom dictionaries if provided\n",
    "    if custom_model_dict is not None:\n",
    "        model_dict = custom_model_dict\n",
    "\n",
    "    if custom_params_dict is not None:\n",
    "        params_dict = custom_params_dict\n",
    "\n",
    "    grid_dict = {}\n",
    "    best_estimators = []\n",
    "    selected_models = {}\n",
    "\n",
    "    # Fit and evaluate models specified in the 'models' list\n",
    "    print(\"\\n[CREATING BASE MODELS]\")\n",
    "    for model_name in models:\n",
    "        if model_name in model_dict:\n",
    "            print(f\"\\n- Optimizing {model_name.upper()}\")\n",
    "            grid = GridSearchCV(model_dict[model_name], params_dict[model_name], cv=5, verbose=0, n_jobs=-1)\n",
    "            grid.fit(X_train, y_train)\n",
    "            grid_dict[model_name] = grid\n",
    "            best_estimators.append((model_name, grid.best_estimator_))\n",
    "            selected_models[model_name.upper()] = grid.best_estimator_\n",
    "            print(f'{model_name.upper()} Best Parameters:', grid.best_params_)\n",
    "            evaluate_binary_model(grid.best_estimator_, f'{model_name.upper()} CLASSIFIER', X_train, X_test, y_train, y_test)\n",
    "\n",
    "    # If additional models are specified, create a voting and stacking classifier, but only if there is more than one model\n",
    "    if best_estimators and len(models) > 1:\n",
    "        print(\"\\n[CREATING VOTING & STACKING ENSEMBLES]\")\n",
    "\n",
    "        # Voting Classifier\n",
    "        print(\"\\n- Creating Voting Classifier\")\n",
    "        voting_clf = VotingClassifier(estimators=best_estimators, voting='soft')\n",
    "        voting_clf.fit(X_train, y_train)\n",
    "        evaluate_binary_model(voting_clf, 'VOTING CLASSIFIER', X_train, X_test, y_train, y_test)\n",
    "\n",
    "        # Stacking Classifier\n",
    "        print(\"\\n- Creating Stacking Classifier\")\n",
    "        stacking_clf = StackingClassifier(classifiers=[est[1] for est in best_estimators], meta_classifier=LogisticRegression())\n",
    "        stacking_clf.fit(X_train, y_train)\n",
    "        evaluate_binary_model(stacking_clf, 'STACKING CLASSIFIER', X_train, X_test, y_train, y_test)\n",
    "\n",
    "    # Feature importances\n",
    "    if selected_models:\n",
    "        mean_importances = np.mean([model.feature_importances_ for model in selected_models.values() if hasattr(model, 'feature_importances_')], axis=0)\n",
    "\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        sns.barplot(x=mean_importances, y=X_train.columns)\n",
    "        plt.title('Mean Feature Importance Plot')\n",
    "        plt.xlabel('Mean Feature Importance')\n",
    "        plt.ylabel('Features')\n",
    "        plt.show()\n",
    "\n",
    "        for model_name, model in selected_models.items():\n",
    "            plot_feature_importance(model, model_name, X_train)\n",
    "\n",
    "        print(\"\\n NOTE: Feature importances are not available for SVC models due to how they work.\")\n",
    "\n",
    "    # Shapley values\n",
    "    for model_name, model in selected_models.items():\n",
    "        plot_shap_values(model, model_name, X_train, multi_class=False)\n",
    "\n",
    "    print(\"\\n NOTE: Shap values are not available for SVC models due to how they work.\")\n",
    "    print(\"\\n NOTE: Shap values are only available for GBM for binary classification at this time.\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4c2ca95313eff533"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# MULTICLASSFLOW"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fbfce6f8f2e939c2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Define your custom model and parameter dictionaries Example\n",
    "#custom_model_dict = {'rf': RandomForestClassifier(random_state=42), \n",
    "#                     'custom_model': MyCustomClassifier()\n",
    "#                     }\n",
    "\n",
    "#custom_params_dict = {'rf': {'n_estimators': [100, 150]}, \n",
    "#                      'custom_model': {'some_param': [1, 2, 3]}\n",
    "#                      }\n",
    "\n",
    "def MultiClassFlow(X_train, X_test, y_train, y_test, models=['xgb', 'lgbm', 'rf', 'gbm', 'svc'], custom_model_dict=None, custom_params_dict=None):\n",
    "    # Always fit and evaluate basic models: Logistic Regression and Naive Bayes\n",
    "    lr_model = LogisticRegression(random_state=42, multi_class='auto')\n",
    "    lr_model.fit(X_train, y_train)\n",
    "\n",
    "    nb_model = GaussianNB()\n",
    "    nb_model.fit(X_train, y_train)\n",
    "\n",
    "    evaluate_multiclass_model(lr_model, 'LOGISTIC REGRESSION CLASSIFIER', X_train, X_test, y_train, y_test)\n",
    "    evaluate_multiclass_model(nb_model, 'NAIVE BAYES CLASSIFIER', X_train, X_test, y_train, y_test)\n",
    "\n",
    "    # Default model and parameter dictionaries\n",
    "    model_dict = {\n",
    "        'xgb': XGBClassifier(random_state=42),\n",
    "        'lgbm': LGBMClassifier(random_state=42),\n",
    "        'rf': RandomForestClassifier(random_state=42),\n",
    "        'gbm': GradientBoostingClassifier(random_state=42),\n",
    "        'svc': SVC(random_state=42, probability=True)\n",
    "    }\n",
    "\n",
    "    params_dict = {\n",
    "        'xgb': {'n_estimators': [100, 150, 300], 'subsample': [None, 0.3, 0.5, 0.8, 0.9], 'colsample_bytree': [0.3, 0.5, 0.8, 1.0]},\n",
    "        'lgbm': {'n_estimators': [100, 150, 300], 'subsample': [None, 0.3, 0.5, 0.8, 0.9], 'colsample_bytree': [0.3, 0.5, 0.8, 1.0]},\n",
    "        'rf': {'n_estimators': [100, 150, 300], 'min_samples_split': [2, 3, 4], 'min_samples_leaf': [1, 2, 3]},\n",
    "        'gbm': {'n_estimators': [100, 150, 300], 'min_samples_split': [2, 3, 4], 'min_samples_leaf': [1, 2, 3]},\n",
    "        'svc': {'C': [0.1, 1, 10], 'kernel': ['rbf', 'poly', 'sigmoid']}\n",
    "    }\n",
    "\n",
    "    # Use custom dictionaries if provided\n",
    "    if custom_model_dict is not None:\n",
    "        model_dict = custom_model_dict\n",
    "\n",
    "    if custom_params_dict is not None:\n",
    "        params_dict = custom_params_dict\n",
    "\n",
    "    grid_dict = {}\n",
    "    best_estimators = []\n",
    "    selected_models = {}\n",
    "\n",
    "    # Fit and evaluate models specified in the 'models' list\n",
    "    print(\"\\n[CREATING BASE MODELS]\")\n",
    "    for model_name in models:\n",
    "        if model_name in model_dict:\n",
    "            print(f\"\\n- Optimizing {model_name.upper()}\")\n",
    "            grid = GridSearchCV(model_dict[model_name], params_dict[model_name], cv=5, verbose=0, n_jobs=-1)\n",
    "            grid.fit(X_train, y_train)\n",
    "            grid_dict[model_name] = grid\n",
    "            best_estimators.append((model_name, grid.best_estimator_))\n",
    "            selected_models[model_name.upper()] = grid.best_estimator_\n",
    "            print(f'{model_name.upper()} Best Parameters:', grid.best_params_)\n",
    "            evaluate_multiclass_model(grid.best_estimator_, f'{model_name.upper()} CLASSIFIER', X_train, X_test, y_train, y_test)\n",
    "\n",
    "    # Ensemble methods\n",
    "    if best_estimators and len(models) > 1:\n",
    "        print(\"\\n[CREATING VOTING & STACKING ENSEMBLES]\")\n",
    "\n",
    "        print(\"\\n- Creating Voting Classifier\")\n",
    "        voting_clf = VotingClassifier(estimators=best_estimators, voting='soft')\n",
    "        voting_clf.fit(X_train, y_train)\n",
    "        evaluate_multiclass_model(voting_clf, 'VOTING CLASSIFIER', X_train, X_test, y_train, y_test)\n",
    "\n",
    "        print(\"\\n- Creating Stacking Classifier\")\n",
    "        stacking_clf = StackingClassifier(classifiers=[est[1] for est in best_estimators], meta_classifier=LogisticRegression())\n",
    "        stacking_clf.fit(X_train, y_train)\n",
    "        evaluate_multiclass_model(stacking_clf, 'STACKING CLASSIFIER', X_train, X_test, y_train, y_test)\n",
    "\n",
    "    # Feature Importances\n",
    "    if selected_models:\n",
    "        mean_importances = np.mean([model.feature_importances_ for model in selected_models.values() if hasattr(model, 'feature_importances_')], axis=0)\n",
    "\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        sns.barplot(x=mean_importances, y=X_train.columns)\n",
    "        plt.title('Mean Feature Importance Plot')\n",
    "        plt.xlabel('Mean Feature Importance')\n",
    "        plt.ylabel('Features')\n",
    "        plt.show()\n",
    "\n",
    "        for model_name, model in selected_models.items():\n",
    "            # Assuming you have a function called plot_feature_importance\n",
    "            plot_feature_importance(model, model_name, X_train)\n",
    "\n",
    "    # Shapley Values\n",
    "    for model_name, model in selected_models.items():\n",
    "        \n",
    "        # Check if the model is gradient boosting machine skip it (not available for multiclass)\n",
    "        if model_name == 'gbm' or model_name == 'GBM': \n",
    "            continue\n",
    "            \n",
    "        # Assuming you have a function called plot_shap_values\n",
    "        plot_shap_values(model, model_name, X_train, multi_class=True)\n",
    "\n",
    "    print(\"\\n NOTE: Shap values are not available for SVC models due to how they work.\")\n",
    "    print(\"\\n NOTE: Shap values are only available for GBM for binary classification at this time.\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "63f9c004e9324c08"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# REGRESSFLOW"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5e199323c71bf8e8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Define your custom model and parameter dictionaries Example\n",
    "#custom_model_dict = {'rf': RandomForesRegresor(random_state=42), \n",
    "#                     'custom_model': MyCustomRegressor()\n",
    "#                     }\n",
    "\n",
    "#custom_params_dict = {'rf': {'n_estimators': [100, 150]}, \n",
    "#                      'custom_model': {'some_param': [1, 2, 3]}\n",
    "#                      }\n",
    "\n",
    "def RegressFlow(X_train, X_test, y_train, y_test, models=['xgb', 'lgbm', 'rf', 'gbm'], custom_model_dict=None, custom_params_dict=None):\n",
    "    # Always fit and evaluate basic model: Linear Regression\n",
    "    lr_model = LinearRegression()\n",
    "    lr_model.fit(X_train, y_train)\n",
    "    evaluate_regression_model(lr_model, 'LINEAR REGRESSION', X_train, X_test, y_train, y_test)\n",
    "\n",
    "    # Default model and parameter dictionaries\n",
    "    model_dict = {\n",
    "        'xgb': XGBRegressor(random_state=42),\n",
    "        'lgbm': LGBMRegressor(random_state=42),\n",
    "        'rf': RandomForestRegressor(random_state=42),\n",
    "        'gbm': GradientBoostingRegressor(random_state=42)\n",
    "    }\n",
    "\n",
    "    params_dict = {\n",
    "        'xgb': {'n_estimators': [100, 150, 300], 'subsample': [None, 0.3, 0.5, 0.8, 0.9], 'colsample_bytree': [0.3, 0.5, 0.8, 1.0]},\n",
    "        'lgbm': {'n_estimators': [100, 150, 300], 'subsample': [None, 0.3, 0.5, 0.8, 0.9], 'colsample_bytree': [0.3, 0.5, 0.8, 1.0]},\n",
    "        'rf': {'n_estimators': [100, 150, 300], 'min_samples_split': [2, 3, 4], 'min_samples_leaf': [1, 2, 3]},\n",
    "        'gbm': {'n_estimators': [100, 150, 300], 'min_samples_split': [2, 3, 4], 'min_samples_leaf': [1, 2, 3]}\n",
    "    }\n",
    "\n",
    "    # Use custom dictionaries if provided\n",
    "    if custom_model_dict is not None:\n",
    "        model_dict = custom_model_dict\n",
    "\n",
    "    if custom_params_dict is not None:\n",
    "        params_dict = custom_params_dict\n",
    "\n",
    "    grid_dict = {}\n",
    "    best_estimators = []\n",
    "    selected_models = {}\n",
    "\n",
    "    # Fit and evaluate models specified in the 'models' list\n",
    "    print(\"\\n[CREATING BASE MODELS]\")\n",
    "    for model_name in models:\n",
    "        if model_name in model_dict:\n",
    "            print(f\"\\n- Optimizing {model_name.upper()}\")\n",
    "            grid = GridSearchCV(model_dict[model_name], params_dict[model_name], cv=5, verbose=0, n_jobs=-1)\n",
    "            grid.fit(X_train, y_train)\n",
    "            grid_dict[model_name] = grid\n",
    "            best_estimators.append((model_name, grid.best_estimator_))\n",
    "            selected_models[model_name.upper()] = grid.best_estimator_\n",
    "            print(f'{model_name.upper()} Best Parameters:', grid.best_params_)\n",
    "            evaluate_regression_model(grid.best_estimator_, f'{model_name.upper()} REGRESSOR', X_train, X_test, y_train, y_test)\n",
    "\n",
    "    # If more than one model is specified, create a voting regressor\n",
    "    if best_estimators and len(models) > 1:\n",
    "        print(\"\\n[CREATING STACKING ENSEMBLE]\")\n",
    "\n",
    "        print(\"\\n- Creating Stacking Regressor\")\n",
    "        stacking_reg = StackingRegressor(regressors=[est[1] for est in best_estimators], meta_regressor=LinearRegression())\n",
    "        stacking_reg.fit(X_train, y_train)\n",
    "        evaluate_regression_model(stacking_reg, 'STACKING REGRESSOR', X_train, X_test, y_train, y_test)\n",
    "\n",
    "    # Feature Importances\n",
    "    if selected_models:\n",
    "        mean_importances = np.mean([model.feature_importances_ for model in selected_models.values() if hasattr(model, 'feature_importances_')], axis=0)\n",
    "\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        sns.barplot(x=mean_importances, y=X_train.columns)\n",
    "        plt.title('Mean Feature Importance Plot')\n",
    "        plt.xlabel('Mean Feature Importance')\n",
    "        plt.ylabel('Features')\n",
    "        plt.show()\n",
    "\n",
    "        for model_name, model in selected_models.items():\n",
    "            plot_feature_importance(model, model_name, X_train)\n",
    "\n",
    "    # Shapley Values\n",
    "    for model_name, model in selected_models.items():\n",
    "        plot_shap_values(model, model_name, X_train, multi_class=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "87df9f777397847b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# BASICS"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a313afef51f0760b"
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "153dd73ad7b6cfa5",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-09-10T01:44:05.637136600Z",
     "start_time": "2023-09-10T01:44:05.361999600Z"
    }
   },
   "outputs": [],
   "source": [
    "# BASICS\n",
    "\n",
    "from sklearn.datasets import make_classification, make_regression\n",
    "\n",
    "def make_sample_data(task='classification', n_samples=1000, n_features=10,\n",
    "                     n_informative=7, n_redundant=3, random_state=42, test_size=0.20):\n",
    "    \"\"\"\n",
    "    Create a sample dataset and split it into training and testing sets.\n",
    "    \n",
    "    Parameters:\n",
    "        task (str): The type of problem to generate data for ('classification' or 'regression').\n",
    "        n_samples (int): The total number of samples.\n",
    "        n_features (int): The total number of features.\n",
    "        n_informative (int): The number of informative features.\n",
    "        n_redundant (int): The number of redundant features.\n",
    "        random_state (int): The seed for random number generator.\n",
    "        test_size (float): The proportion of the dataset to include in the test split.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: X_train, X_test, y_train, y_test (as Pandas DataFrame and Series)\n",
    "    \"\"\"\n",
    "\n",
    "    if task == 'classification':\n",
    "        # Create a classification dataset\n",
    "        X, y = make_classification(n_samples=n_samples, n_features=n_features,\n",
    "                                   n_informative=n_informative, n_redundant=n_redundant,\n",
    "                                   random_state=random_state)\n",
    "    elif task == 'regression':\n",
    "        # Create a regression dataset\n",
    "        X, y = make_regression(n_samples=n_samples, n_features=n_features,\n",
    "                               n_informative=n_informative, noise=0.1,\n",
    "                               random_state=random_state)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid task. Choose either 'classification' or 'regression'.\")\n",
    "\n",
    "    # Split the dataset into training and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "\n",
    "    # Convert to Pandas DataFrame and Series\n",
    "    feature_names = [f'feature_{i}' for i in range(1, n_features+1)]\n",
    "    X_train = pd.DataFrame(X_train, columns=feature_names)\n",
    "    X_test = pd.DataFrame(X_test, columns=feature_names)\n",
    "    y_train = pd.Series(y_train, name='target')\n",
    "    y_test = pd.Series(y_test, name='target')\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def manual_dropper(dataframe, columns_to_manually_drop):\n",
    "    \"\"\"\n",
    "    Purpose:\n",
    "    Manually drop specified columns from a given DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "        - dataframe (pd.DataFrame): DataFrame from which columns will be dropped\n",
    "        - columns_to_manually_drop (list): List of column names to drop\n",
    "\n",
    "    Returns:\n",
    "        - pd.DataFrame: DataFrame with specified columns removed\n",
    "    \"\"\"\n",
    "    for col in columns_to_manually_drop:\n",
    "        if col in dataframe.columns:\n",
    "            dataframe = dataframe.drop(columns=col)\n",
    "            print(f'Dropped {col} column')\n",
    "        else:\n",
    "            print(f'Warning: {col} column not found in DataFrame, unable to drop it')\n",
    "    return dataframe\n",
    "\n",
    "def ensure_data_types(X_train, X_test, y_train, y_test):\n",
    "    \"\"\"\n",
    "    Purpose:\n",
    "    Ensure that training and testing data are of correct types.\n",
    "\n",
    "    Parameters:\n",
    "        - X_train, X_test: Training and testing feature sets\n",
    "        - y_train, y_test: Training and testing labels\n",
    "\n",
    "    Returns:\n",
    "        - (pd.DataFrame, pd.DataFrame, pd.Series, pd.Series): \n",
    "          X_train, X_test, y_train, y_test in DataFrame or Series format\n",
    "    \"\"\"\n",
    "    X_train = pd.DataFrame(X_train)\n",
    "    X_test = pd.DataFrame(X_test)\n",
    "    y_train = pd.Series(y_train)\n",
    "    y_test = pd.Series(y_test)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def ensure_data_types_and_show(X_train, X_test, y_train, y_test):\n",
    "    \"\"\"\n",
    "    Purpose:\n",
    "    Ensure that training and testing data are of correct types, and display the first 5 rows of each DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "        - X_train, X_test: Training and testing feature sets\n",
    "        - y_train, y_test: Training and testing labels\n",
    "\n",
    "    Returns:\n",
    "        - (pd.DataFrame, pd.DataFrame, pd.Series, pd.Series): \n",
    "          X_train, X_test, y_train, y_test in DataFrame or Series format\n",
    "    \"\"\"\n",
    "    X_train = pd.DataFrame(X_train)\n",
    "    X_test = pd.DataFrame(X_test)\n",
    "    y_train = pd.Series(y_train)\n",
    "    y_test = pd.Series(y_test)\n",
    "\n",
    "    print(\"\\nFirst 5 rows of the training dataframe:\")\n",
    "    display(X_train.head())\n",
    "\n",
    "    print(\"\\nFirst 5 rows of the testing dataframe:\")\n",
    "    display(X_test.head())\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "def optimal_bins(dataframe, list_of_columns_to_check, method='auto',\n",
    "                 return_ordinal_bins=False, plot_bins=True, print_edges=False):\n",
    "    \"\"\"\n",
    "    Purpose:\n",
    "    Optimize and plot histogram bins for specified numerical columns in a DataFrame. Optionally prints the bin edges.\n",
    "\n",
    "    Parameters:\n",
    "        - dataframe (pd.DataFrame): The DataFrame containing the data to be binned.\n",
    "        - list_of_columns_to_check (list): List of column names in the DataFrame for which bins should be optimized.\n",
    "        - method (str): The method used for bin optimization (default='auto'). Refer to numpy.histogram_bin_edges for available methods.\n",
    "        - return_ordinal_bins (bool): If True, returns DataFrame with ordinal bins instead of the original data (default=False).\n",
    "        - plot_bins (bool): If True, plots the histograms for each column specified (default=True).\n",
    "        - print_edges (bool): If True, prints the bin edges and their labels after each plot (default=False).\n",
    "\n",
    "    Returns:\n",
    "        - pd.DataFrame: Updated DataFrame with ordinal bins if return_ordinal_bins is True. Otherwise, None.\n",
    "\n",
    "    Note:\n",
    "    The function will issue a warning and skip the column if it is not found in the DataFrame.\n",
    "    \"\"\"\n",
    "    sns.set(style=\"whitegrid\")\n",
    "    df_ordinal_bins = dataframe[list_of_columns_to_check].copy()\n",
    "\n",
    "    for column in list_of_columns_to_check:\n",
    "        if column not in dataframe.columns:\n",
    "            print(f\"Warning: Column '{column}' not found in DataFrame. Skipping...\")\n",
    "            continue\n",
    "\n",
    "        if dataframe[column].dtype in ['int64', 'float64']:\n",
    "            data = dataframe[column].dropna()\n",
    "            bin_edges = np.histogram_bin_edges(data, bins=method)\n",
    "\n",
    "            num_bins = int(np.floor(len(bin_edges) - 1))\n",
    "            bin_edges = np.histogram_bin_edges(data, bins=num_bins)\n",
    "\n",
    "            if plot_bins:\n",
    "                plt.figure(figsize=(12, 6))\n",
    "                colors = sns.color_palette(\"husl\", num_bins)\n",
    "                legend_labels = []\n",
    "                for i in range(num_bins):\n",
    "                    sns.histplot(data, bins=[bin_edges[i], bin_edges[i + 1]], kde=False, color=colors[i])\n",
    "                    legend_labels.append(f'Bin {i+1} [{bin_edges[i]:.2f} to {bin_edges[i+1]:.2f}]')\n",
    "\n",
    "                plt.legend(title='Bins', labels=legend_labels, loc='upper left', bbox_to_anchor=(1, 1))\n",
    "                plt.title(f'{column} - {method.capitalize()} Bins')\n",
    "                plt.tight_layout(rect=[0, 0, 0.85, 1])\n",
    "                plt.show()\n",
    "\n",
    "            if print_edges:\n",
    "                print(f\"Column: {column}\")\n",
    "                for i in range(num_bins):\n",
    "                    print(f'Bin {i+1} [{bin_edges[i]:.2f} to {bin_edges[i+1]:.2f}]')\n",
    "\n",
    "            if return_ordinal_bins:\n",
    "                df_ordinal_bins[column] = pd.cut(dataframe[column], bins=bin_edges,\n",
    "                                                 labels=False, right=False).astype(pd.Int64Dtype(), errors='ignore')\n",
    "\n",
    "    if return_ordinal_bins:\n",
    "        dataframe.update(df_ordinal_bins)\n",
    "        return dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# TRAIN TEST SPLITS"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "52b82f04f1235394"
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [],
   "source": [
    "# TRAIN TEST SPLITS\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit\n",
    "\n",
    "def split_dataframe(df, test_size=0.2, random_state=42, target_column='target', stratified=False):\n",
    "    \"\"\"\n",
    "    Purpose:\n",
    "    Split a DataFrame into training and testing sets for features and labels.\n",
    "\n",
    "    Parameters:\n",
    "        - df (pd.DataFrame): DataFrame to be split\n",
    "        - test_size (float): Proportion of the dataset to include in the test split (default=0.2)\n",
    "        - random_state (int): The seed used by the random number generator (default=42)\n",
    "        - target_column (str): The name of the target (label) column (default='target')\n",
    "        - stratified (bool): Whether to perform stratified sampling (default=False)\n",
    "\n",
    "    Returns:\n",
    "        - (pd.DataFrame, pd.DataFrame, pd.Series, pd.Series): \n",
    "          X_train, X_test, y_train, y_test as DataFrame or Series\n",
    "    \"\"\"\n",
    "    if stratified:\n",
    "        sss = StratifiedShuffleSplit(n_splits=1, test_size=test_size, random_state=random_state)\n",
    "        for train_index, test_index in sss.split(df.drop([target_column], axis=1), df[target_column]):\n",
    "            X_train = df.drop([target_column], axis=1).iloc[train_index]\n",
    "            y_train = df[target_column].iloc[train_index]\n",
    "            X_test = df.drop([target_column], axis=1).iloc[test_index]\n",
    "            y_test = df[target_column].iloc[test_index]\n",
    "    else:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            df.drop([target_column], axis=1), df[target_column], test_size=test_size, random_state=random_state\n",
    "        )\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-10T01:44:05.662261700Z",
     "start_time": "2023-09-10T01:44:05.379821600Z"
    }
   },
   "id": "76fa98ae9eb33918"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# IMPUTATION"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "405d24fab0fd329e"
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [],
   "source": [
    "# IMPUTATION\n",
    "\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer, SimpleImputer\n",
    "\n",
    "def validate_columns(columns, X_train, y_train, imputation_name):\n",
    "    \"\"\"\n",
    "    Purpose:\n",
    "    Validate that the specified columns for imputation exist in the training data.\n",
    "\n",
    "    Parameters:\n",
    "        - columns (list): List of columns to be imputed\n",
    "        - X_train (pd.DataFrame): Training feature set\n",
    "        - y_train (pd.Series): Training labels\n",
    "        - imputation_name (str): Name of the imputation method being used\n",
    "\n",
    "    Returns:\n",
    "        - bool: True if all columns are valid, False otherwise\n",
    "    \"\"\"\n",
    "    if not columns:\n",
    "        print(f\"No columns were specified for {imputation_name} imputation.\")\n",
    "    else:\n",
    "        print(f\"{', '.join(columns)} were specified for {imputation_name} imputation.\")\n",
    "    invalid_columns = [column for column in columns if column not in X_train.columns and column != y_train.name]\n",
    "    if invalid_columns:\n",
    "        print(f\"{imputation_name} ran into invalid column names: {', '.join(invalid_columns)}\")\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def mean_imputation(X_train, X_test, y_train, y_test, mean_imputation_columns):\n",
    "    \"\"\"\n",
    "    Purpose:\n",
    "    Perform mean imputation on specified columns of training and testing sets.\n",
    "\n",
    "    Parameters:\n",
    "        - X_train, X_test (pd.DataFrame): Training and testing feature sets\n",
    "        - y_train, y_test (pd.Series): Training and testing labels\n",
    "        - mean_imputation_columns (list): List of columns on which to perform mean imputation\n",
    "\n",
    "    Returns:\n",
    "        - (pd.DataFrame, pd.DataFrame, pd.Series, pd.Series): \n",
    "          X_train, X_test, y_train, y_test with mean imputation applied\n",
    "    \"\"\"\n",
    "    if not validate_columns(mean_imputation_columns, X_train, y_train, \"Mean\"):\n",
    "        return X_train, X_test, y_train, y_test\n",
    "\n",
    "    imputer = SimpleImputer(strategy='mean')\n",
    "    for column in mean_imputation_columns:\n",
    "        if column == y_train.name:\n",
    "            imputer.fit(y_train.to_frame())\n",
    "            y_train = pd.Series(imputer.transform(y_train.to_frame()).flatten(), name=y_train.name)\n",
    "            y_test = pd.Series(imputer.transform(y_test.to_frame()).flatten(), name=y_test.name)\n",
    "        else:\n",
    "            imputer.fit(X_train[[column]])\n",
    "            X_train[column] = imputer.transform(X_train[[column]])\n",
    "            X_test[column] = imputer.transform(X_test[[column]])\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def trimmed_mean_imputation(X_train, X_test, y_train, y_test, trimmed_mean_imputation_columns):\n",
    "    \"\"\"\n",
    "    Purpose:\n",
    "    Perform trimmed mean imputation on specified columns of training and testing sets.\n",
    "\n",
    "    Parameters:\n",
    "        - X_train, X_test (pd.DataFrame): Training and testing feature sets\n",
    "        - y_train, y_test (pd.Series): Training and testing labels\n",
    "        - trimmed_mean_imputation_columns (list): List of columns on which to perform trimmed mean imputation\n",
    "\n",
    "    Returns:\n",
    "        - (pd.DataFrame, pd.DataFrame, pd.Series, pd.Series): \n",
    "          X_train, X_test, y_train, y_test with trimmed mean imputation applied\n",
    "    \"\"\"\n",
    "    if not validate_columns(trimmed_mean_imputation_columns, X_train, y_train, \"Trimmed Mean\"):\n",
    "        return X_train, X_test, y_train, y_test\n",
    "\n",
    "    def trimmed_mean(values):\n",
    "        non_null_values = [value for value in values if pd.notnull(value)]\n",
    "        trim_percentage = 0.1\n",
    "        trim_size = int(trim_percentage * len(non_null_values))\n",
    "        trimmed_values = sorted(non_null_values)[trim_size:-trim_size]\n",
    "        trimmed_mean = np.mean(trimmed_values)\n",
    "        return trimmed_mean\n",
    "\n",
    "    for column in trimmed_mean_imputation_columns:\n",
    "        imputer = SimpleImputer(strategy=trimmed_mean)\n",
    "        if column == y_train.name:\n",
    "            imputer.fit(y_train.to_frame())\n",
    "            y_train = pd.Series(imputer.transform(y_train.to_frame()).flatten(), name=y_train.name)\n",
    "            y_test = pd.Series(imputer.transform(y_test.to_frame()).flatten(), name=y_test.name)\n",
    "        else:\n",
    "            imputer.fit(X_train[[column]])\n",
    "            X_train[column] = imputer.transform(X_train[[column]])\n",
    "            X_test[column] = imputer.transform(X_test[[column]])\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def median_imputation(X_train, X_test, y_train, y_test, median_imputation_columns):\n",
    "    \"\"\"\n",
    "    Purpose:\n",
    "    Perform median imputation on specified columns of training and testing sets.\n",
    "\n",
    "    Parameters:\n",
    "        - X_train, X_test (pd.DataFrame): Training and testing feature sets\n",
    "        - y_train, y_test (pd.Series): Training and testing labels\n",
    "        - median_imputation_columns (list): List of columns on which to perform median imputation\n",
    "\n",
    "    Returns:\n",
    "        - (pd.DataFrame, pd.DataFrame, pd.Series, pd.Series): \n",
    "          X_train, X_test, y_train, y_test with median imputation applied\n",
    "    \"\"\"\n",
    "    if not validate_columns(median_imputation_columns, X_train, y_train, \"Median\"):\n",
    "        return X_train, X_test, y_train, y_test\n",
    "\n",
    "    imputer = SimpleImputer(strategy='median')\n",
    "    for column in median_imputation_columns:\n",
    "        if column == y_train.name:\n",
    "            imputer.fit(y_train.to_frame())\n",
    "            y_train = pd.Series(imputer.transform(y_train.to_frame()).flatten(), name=y_train.name)\n",
    "            y_test = pd.Series(imputer.transform(y_test.to_frame()).flatten(), name=y_test.name)\n",
    "        else:\n",
    "            imputer.fit(X_train[[column]])\n",
    "            X_train[column] = imputer.transform(X_train[[column]])\n",
    "            X_test[column] = imputer.transform(X_test[[column]])\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def mode_imputation(X_train, X_test, y_train, y_test, mode_imputation_columns):\n",
    "    \"\"\"\n",
    "    Purpose:\n",
    "    Perform mode imputation on specified columns of training and testing sets.\n",
    "\n",
    "    Parameters:\n",
    "        - X_train, X_test (pd.DataFrame): Training and testing feature sets\n",
    "        - y_train, y_test (pd.Series): Training and testing labels\n",
    "        - mode_imputation_columns (list): List of columns on which to perform mode imputation\n",
    "\n",
    "    Returns:\n",
    "        - (pd.DataFrame, pd.DataFrame, pd.Series, pd.Series): \n",
    "          X_train, X_test, y_train, y_test with mode imputation applied\n",
    "    \"\"\"\n",
    "    if not validate_columns(mode_imputation_columns, X_train, y_train, \"Mode\"):\n",
    "        return X_train, X_test, y_train, y_test\n",
    "\n",
    "    imputer = SimpleImputer(strategy='most_frequent')\n",
    "    for column in mode_imputation_columns:\n",
    "        if column == y_train.name:\n",
    "            imputer.fit(y_train.to_frame())\n",
    "            y_train = pd.Series(imputer.transform(y_train.to_frame()).flatten(), name=y_train.name)\n",
    "            y_test = pd.Series(imputer.transform(y_test.to_frame()).flatten(), name=y_test.name)\n",
    "        else:\n",
    "            imputer.fit(X_train[[column]])\n",
    "            X_train[column] = imputer.transform(X_train[[column]])\n",
    "            X_test[column] = imputer.transform(X_test[[column]])\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def iterative_imputation(X_train, X_test, y_train, y_test, iterative_imputation_columns):\n",
    "    \"\"\"\n",
    "    Purpose:\n",
    "    Perform iterative imputation on specified columns of training and testing sets.\n",
    "\n",
    "    Parameters:\n",
    "        - X_train, X_test (pd.DataFrame): Training and testing feature sets\n",
    "        - y_train, y_test (pd.Series): Training and testing labels\n",
    "        - iterative_imputation_columns (list): List of columns on which to perform iterative imputation\n",
    "\n",
    "    Returns:\n",
    "        - (pd.DataFrame, pd.DataFrame, pd.Series, pd.Series): \n",
    "          X_train, X_test, y_train, y_test with iterative imputation applied\n",
    "    \"\"\"\n",
    "    if not validate_columns(iterative_imputation_columns, X_train, y_train, \"Iterative\"):\n",
    "        return X_train, X_test, y_train, y_test\n",
    "\n",
    "    imputer = IterativeImputer(estimator=LinearRegression())\n",
    "    for column in iterative_imputation_columns:\n",
    "        if column == y_train.name:\n",
    "            imputer.fit(y_train.to_frame())\n",
    "            y_train = pd.Series(imputer.transform(y_train.to_frame()).flatten(), name=y_train.name)\n",
    "            y_test = pd.Series(imputer.transform(y_test.to_frame()).flatten(), name=y_test.name)\n",
    "        else:\n",
    "            imputer.fit(X_train[[column]])\n",
    "            X_train[column] = imputer.transform(X_train[[column]])\n",
    "            X_test[column] = imputer.transform(X_test[[column]])\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def missing_value_checker(X_train, X_test, y_train, y_test):\n",
    "    \"\"\"\n",
    "    Purpose:\n",
    "    Check for missing values in the training and testing datasets.\n",
    "\n",
    "    Parameters:\n",
    "        - X_train, X_test (pd.DataFrame): Training and testing feature sets\n",
    "        - y_train, y_test (pd.Series): Training and testing labels\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    datasets = {\"X_train\": X_train, \"X_test\": X_test, \"y_train\": y_train, \"y_test\": y_test}\n",
    "    columns_with_missings = {}\n",
    "\n",
    "    for name, dataset in datasets.items():\n",
    "        if isinstance(dataset, pd.DataFrame):\n",
    "            missing_columns = dataset.columns[dataset.isnull().any()].tolist()\n",
    "        elif isinstance(dataset, pd.Series):\n",
    "            missing_columns = [dataset.name] if dataset.isnull().any() else []\n",
    "\n",
    "        if missing_columns:\n",
    "            columns_with_missings[name] = missing_columns\n",
    "\n",
    "    if columns_with_missings:\n",
    "        print(\"Missing values found in the following columns:\")\n",
    "        for name, missing_columns in columns_with_missings.items():\n",
    "            print(f\"{name}: {', '.join(missing_columns)}\")\n",
    "    else:\n",
    "        print(\"No missing values found in the datasets.\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-10T01:44:05.695036400Z",
     "start_time": "2023-09-10T01:44:05.403312600Z"
    }
   },
   "id": "d2b556d2e24343d7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# ENCODING"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5062598b4a020849"
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [
    "# ENCODING\n",
    "\n",
    "from category_encoders import TargetEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "def target_encode(X_train, X_test, y_train, y_test, list_of_columns_to_target_encode):\n",
    "    \"\"\"\n",
    "    Purpose:\n",
    "    Perform target encoding on specified columns of training and testing feature sets.\n",
    "\n",
    "    Parameters:\n",
    "        - X_train, X_test (pd.DataFrame): Training and testing feature sets\n",
    "        - y_train, y_test (pd.Series): Training and testing labels\n",
    "        - list_of_columns_to_target_encode (list): List of columns to be target encoded\n",
    "\n",
    "    Returns:\n",
    "        - (pd.DataFrame, pd.DataFrame): X_train_encoded, X_test_encoded with target encoding applied\n",
    "    \"\"\"\n",
    "    print(\"[TARGET ENCODING CHOSEN]\\n\")\n",
    "    print(\"Columns being target encoded: \", list_of_columns_to_target_encode)\n",
    "    encoder = TargetEncoder(cols=list_of_columns_to_target_encode)\n",
    "    X_train_encoded = encoder.fit_transform(X_train, y_train)\n",
    "    X_test_encoded = encoder.transform(X_test)\n",
    "    return X_train_encoded, X_test_encoded\n",
    "\n",
    "def one_hot_encode(X_train, X_test, list_of_columns_to_one_hot_encode, drops=0):\n",
    "    \"\"\"\n",
    "    Purpose:\n",
    "    Perform one-hot encoding on specified columns of training and testing feature sets.\n",
    "\n",
    "    Parameters:\n",
    "        - X_train, X_test (pd.DataFrame): Training and testing feature sets\n",
    "        - list_of_columns_to_one_hot_encode (list): List of columns to be one-hot encoded\n",
    "        - drops (int): Number of one-hot encoded columns to drop to avoid multicollinearity (default=0)\n",
    "\n",
    "    Returns:\n",
    "        - (pd.DataFrame, pd.DataFrame): X_train_encoded, X_test_encoded with one-hot encoding applied\n",
    "    \"\"\"\n",
    "    print(\"[ONE HOT ENCODING CHOSEN]\\n\")\n",
    "    print(\"Columns being one-hot encoded: \", list_of_columns_to_one_hot_encode)\n",
    "    encoder = OneHotEncoder()\n",
    "    X_train_encoded = X_train.copy()\n",
    "    X_test_encoded = X_test.copy()\n",
    "\n",
    "    for col in list_of_columns_to_one_hot_encode:\n",
    "        enc = encoder.fit_transform(X_train[[col]])\n",
    "        enc_test = encoder.transform(X_test[[col]])\n",
    "\n",
    "        for i in range(drops, enc.shape[1]):\n",
    "            X_train_encoded[col + '_' + str(i - drops)] = enc[:, i].toarray().ravel().astype(int)\n",
    "            X_test_encoded[col + '_' + str(i - drops)] = enc_test[:, i].toarray().ravel().astype(int)\n",
    "\n",
    "        X_train_encoded.drop(columns=[col], inplace=True)\n",
    "        X_test_encoded.drop(columns=[col], inplace=True)\n",
    "\n",
    "    return X_train_encoded, X_test_encoded\n",
    "\n",
    "def woe_encode(X_train, X_test, y_train, y_test, list_of_columns_to_woe_encode):\n",
    "    \"\"\"\n",
    "    Purpose:\n",
    "    Perform Weight of Evidence (WoE) encoding on specified columns of training and testing feature sets.\n",
    "\n",
    "    Parameters:\n",
    "        - X_train, X_test (pd.DataFrame): Training and testing feature sets\n",
    "        - y_train, y_test (pd.Series): Training and testing labels\n",
    "        - list_of_columns_to_woe_encode (list): List of columns to be WoE encoded\n",
    "\n",
    "    Returns:\n",
    "        - (pd.DataFrame, pd.DataFrame): X_train_encoded, X_test_encoded with WoE encoding applied\n",
    "    \"\"\"\n",
    "    unique_values = y_train.nunique()\n",
    "    if unique_values > 2:\n",
    "        print(\"WARNING: WoE encoding is traditionally used for binary classification. \"\n",
    "              \"Your y_train has more than two unique values. A different encoding method might be more suitable.\")\n",
    "\n",
    "    print(\"[WOE ENCODING CHOSEN]\\n\")\n",
    "    print(\"Columns being WoE encoded: \", list_of_columns_to_woe_encode)\n",
    "\n",
    "    # Assuming WOEEncoder is imported from category_encoders\n",
    "    encoder = WOEEncoder(cols=list_of_columns_to_woe_encode)\n",
    "    X_train_encoded = encoder.fit_transform(X_train, y_train)\n",
    "    X_test_encoded = encoder.transform(X_test)\n",
    "\n",
    "    return X_train_encoded, X_test_encoded"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-10T01:44:05.701950900Z",
     "start_time": "2023-09-10T01:44:05.428224100Z"
    }
   },
   "id": "1121e2e27c014957"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# DATA TRANSFORMS"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f25fda9d2e9da9f5"
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [],
   "source": [
    "# DATA TRANSFORMS\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "def data_transformations(X_train, X_test, y_train, y_test, list_of_columns_to_transform, transformation_type=\"boxcox\"):\n",
    "    \"\"\"\n",
    "    Purpose:\n",
    "    Apply various transformations to specified columns of training and testing datasets \n",
    "    to make the data more closely follow a normal distribution. \n",
    "\n",
    "    Parameters:\n",
    "        - X_train, X_test (pd.DataFrame): Training and testing feature sets\n",
    "        - y_train, y_test (pd.Series or array-like): Training and testing labels\n",
    "        - list_of_columns_to_transform (list): List of column names to apply transformation\n",
    "        - transformation_type (str): The type of transformation to apply (\"boxcox\", \"log\", \"sqrt\")\n",
    "\n",
    "    Returns:\n",
    "        - (pd.DataFrame, pd.DataFrame, pd.Series, pd.Series): Transformed X_train, X_test, y_train, y_test\n",
    "\n",
    "    Note:\n",
    "    The function also plots histograms and QQ plots before and after the transformation, \n",
    "    as well as printing out Shapiro-Wilk and Anderson-Darling test statistics.\n",
    "    \"\"\"\n",
    "    \n",
    "    transformed_X_train = X_train.copy()\n",
    "    transformed_X_test = X_test.copy()\n",
    "    transformed_y_train = pd.Series(y_train) if not isinstance(y_train, pd.Series) else y_train.copy()\n",
    "    transformed_y_test = pd.Series(y_test) if not isinstance(y_test, pd.Series) else y_test.copy()\n",
    "\n",
    "    for col in list_of_columns_to_transform:\n",
    "        data_to_transform = transformed_X_train[col] if col in transformed_X_train.columns else transformed_y_train\n",
    "        test_data_to_transform = transformed_X_test[col] if col in transformed_X_test.columns else transformed_y_test\n",
    "\n",
    "        # For transformations that require strictly positive data, find the minimum value and shift all data\n",
    "        if transformation_type in [\"boxcox\", \"log\"]:\n",
    "            min_val = min(data_to_transform.min(), test_data_to_transform.min())\n",
    "            shift_val = abs(min_val) + 1e-8  # Make it strictly positive\n",
    "            data_to_transform += shift_val\n",
    "            test_data_to_transform += shift_val\n",
    "\n",
    "        # Plot and show stats for training data before transformation\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(15, 4))\n",
    "        sns.histplot(data_to_transform, kde=True, ax=axes[0])\n",
    "        stats.probplot(data_to_transform, plot=axes[1])\n",
    "        axes[0].set_title(f'{col} Distribution in Training Data (Before Transformation)')\n",
    "        axes[1].set_title(f'{col} QQ Plot in Training Data (Before Transformation)')\n",
    "        plt.show()\n",
    "\n",
    "        shapiro_test_stat, shapiro_p_value = stats.shapiro(data_to_transform)\n",
    "        anderson_result = stats.anderson(data_to_transform)\n",
    "        print(f\"Training Data '{col}' (Before Transformation):\\nShapiro-Wilk: Statistic = {shapiro_test_stat}, p-value = {shapiro_p_value}\\nAnderson-Darling: Statistic = {anderson_result.statistic}, Critical Values = {anderson_result.critical_values}\")\n",
    "\n",
    "        # Plot and show stats for test data before transformation\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(15, 4))\n",
    "        sns.histplot(test_data_to_transform, kde=True, ax=axes[0])\n",
    "        stats.probplot(test_data_to_transform, plot=axes[1])\n",
    "        axes[0].set_title(f'{col} Distribution in Test Data (Before Transformation)')\n",
    "        axes[1].set_title(f'{col} QQ Plot in Test Data (Before Transformation)')\n",
    "        plt.show()\n",
    "\n",
    "        shapiro_test_stat, shapiro_p_value = stats.shapiro(test_data_to_transform)\n",
    "        anderson_result = stats.anderson(test_data_to_transform)\n",
    "        print(f\"Test Data '{col}' (Before Transformation):\\nShapiro-Wilk: Statistic = {shapiro_test_stat}, p-value = {shapiro_p_value}\\nAnderson-Darling: Statistic = {anderson_result.statistic}, Critical Values = {anderson_result.critical_values}\")\n",
    "         \n",
    "        # Apply appropriate transformation\n",
    "        if transformation_type == \"boxcox\":\n",
    "            data_to_transform, optimal_lambda = stats.boxcox(data_to_transform)\n",
    "            test_data_to_transform = stats.boxcox(test_data_to_transform, lmbda=optimal_lambda)\n",
    "        elif transformation_type == \"log\":\n",
    "            data_to_transform = np.log(data_to_transform)\n",
    "            test_data_to_transform = np.log(test_data_to_transform)\n",
    "        elif transformation_type == \"sqrt\":\n",
    "            data_to_transform = np.sqrt(data_to_transform)\n",
    "            test_data_to_transform = np.sqrt(test_data_to_transform)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid transformation_type. Choose from 'boxcox', 'log', 'sqrt'.\")\n",
    "\n",
    "        # Update the transformed data frames\n",
    "        if col in transformed_X_train.columns:\n",
    "            transformed_X_train[col] = data_to_transform\n",
    "            transformed_X_test[col] = test_data_to_transform\n",
    "        else:\n",
    "            transformed_y_train = data_to_transform\n",
    "            transformed_y_test = test_data_to_transform\n",
    "\n",
    "        # Plot and show stats for training data after transformation\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(15, 4))\n",
    "        sns.histplot(data_to_transform, kde=True, ax=axes[0])\n",
    "        stats.probplot(data_to_transform, plot=axes[1])\n",
    "        axes[0].set_title(f'{col} Distribution in Training Data (After Transformation)')\n",
    "        axes[1].set_title(f'{col} QQ Plot in Training Data (After Transformation)')\n",
    "        plt.show()\n",
    "\n",
    "        shapiro_test_stat, shapiro_p_value = stats.shapiro(data_to_transform)\n",
    "        anderson_result = stats.anderson(data_to_transform)\n",
    "        print(f\"Training Data '{col}' (After Transformation):\\nShapiro-Wilk: Statistic = {shapiro_test_stat}, p-value = {shapiro_p_value}\\nAnderson-Darling: Statistic = {anderson_result.statistic}, Critical Values = {anderson_result.critical_values}\")\n",
    "\n",
    "        # Plot and show stats for test data after transformation\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(15, 4))\n",
    "        sns.histplot(test_data_to_transform, kde=True, ax=axes[0])\n",
    "        stats.probplot(test_data_to_transform, plot=axes[1])\n",
    "        axes[0].set_title(f'{col} Distribution in Test Data (After Transformation)')\n",
    "        axes[1].set_title(f'{col} QQ Plot in Test Data (After Transformation)')\n",
    "        plt.show()\n",
    "\n",
    "        shapiro_test_stat, shapiro_p_value = stats.shapiro(test_data_to_transform)\n",
    "        anderson_result = stats.anderson(test_data_to_transform)\n",
    "        print(f\"Test Data '{col}' (After Transformation):\\nShapiro-Wilk: Statistic = {shapiro_test_stat}, p-value = {shapiro_p_value}\\nAnderson-Darling: Statistic = {anderson_result.statistic}, Critical Values = {anderson_result.critical_values}\")\n",
    "\n",
    "    return transformed_X_train, transformed_X_test, transformed_y_train, transformed_y_test"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-10T01:44:05.717223300Z",
     "start_time": "2023-09-10T01:44:05.448912800Z"
    }
   },
   "id": "e8e69a6af045094f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# OUTLIER REMOVAL"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "41ff0f693358dce7"
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [],
   "source": [
    "# OUTLIER REMOVAL\n",
    "\n",
    "from scipy.stats import iqr, zscore\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "\n",
    "def remove_outliers(X_train, X_test, y_train, y_test, method=None, apply_to_test_data=False):\n",
    "    \"\"\"\n",
    "    Purpose:\n",
    "    Remove outliers from the training and testing datasets using different methods.\n",
    "\n",
    "    Parameters:\n",
    "        - X_train, X_test (pd.DataFrame): Training and testing feature sets\n",
    "        - y_train, y_test (pd.Series or array-like): Training and testing labels\n",
    "        - method (str): Method to use for outlier removal. Options are:\n",
    "            - 'iqr': Interquartile Range\n",
    "            - 'zscore': Z-Score\n",
    "            - 'isolation': Isolation Forest\n",
    "            - 'lof': Local Outlier Factor\n",
    "        - apply_to_test_data (bool): Whether to apply outlier removal to test data (default=False)\n",
    "\n",
    "    Returns:\n",
    "        - (pd.DataFrame, pd.DataFrame, pd.Series, pd.Series): X_train, X_test, y_train, y_test with outliers removed\n",
    "\n",
    "    Note:\n",
    "    The function also prints the method chosen and the parameters used for outlier removal.\n",
    "    \"\"\"\n",
    "    print(\"[OUTLIER REMOVAL]\\n\")\n",
    "\n",
    "    if method == 'iqr':\n",
    "        print(\"Outlier Removal Method Chosen: IQR\")\n",
    "\n",
    "        Q1 = X_train.quantile(0.25)\n",
    "        Q3 = X_train.quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_scalar = 1.5\n",
    "        upper_scalar = 1.5\n",
    "        lower_bound = Q1 - lower_scalar * IQR\n",
    "        upper_bound = Q3 + upper_scalar * IQR\n",
    "        print(f\"Outlier Parameters Used: Lower Scalar = {lower_scalar}, Upper Scalar = {upper_scalar}\")\n",
    "\n",
    "        X_train = X_train[(X_train >= lower_bound) & (X_train <= upper_bound)].dropna()\n",
    "        y_train = y_train.loc[X_train.index]\n",
    "\n",
    "        if apply_to_test_data:\n",
    "            X_test = X_test[(X_test >= lower_bound) & (X_test <= upper_bound)].dropna()\n",
    "            y_test = y_test.loc[X_test.index]\n",
    "\n",
    "    elif method == 'zscore':\n",
    "        print(\"Outlier Removal Method Chosen: Z-Score\")\n",
    "\n",
    "        threshold = 3\n",
    "        print(f\"Outlier Parameters Used: Threshold = {threshold}\")\n",
    "\n",
    "        z_scores = abs(zscore(X_train))\n",
    "        X_train = X_train[(z_scores < threshold).all(axis=1)]\n",
    "        y_train = y_train.loc[X_train.index]\n",
    "\n",
    "        if apply_to_test_data:\n",
    "            z_scores_test = abs(zscore(X_test))\n",
    "            X_test = X_test[(z_scores_test < threshold).all(axis=1)]\n",
    "            y_test = y_test.loc[X_test.index]\n",
    "\n",
    "    elif method == 'isolation':\n",
    "        print(\"Outlier Removal Method Chosen: Isolation Forest\")\n",
    "\n",
    "        contamination = 0.05\n",
    "        print(f\"Outlier Parameters Used: Contamination = {contamination}\")\n",
    "\n",
    "        model = IsolationForest(contamination=contamination)\n",
    "        model.fit(X_train)\n",
    "        outliers = model.predict(X_train) == -1\n",
    "        X_train = X_train[~outliers]\n",
    "        y_train = y_train.loc[X_train.index]\n",
    "\n",
    "        if apply_to_test_data:\n",
    "            outliers_test = model.predict(X_test) == -1\n",
    "            X_test = X_test[~outliers_test]\n",
    "            y_test = y_test.loc[X_test.index]\n",
    "\n",
    "    elif method == 'lof':\n",
    "        print(\"Outlier Removal Method Chosen: Local Outlier Factor\")\n",
    "\n",
    "        n_neighbors = 20\n",
    "        contamination = 'auto'\n",
    "        print(f\"Outlier Parameters Used: n_neighbors = {n_neighbors}, contamination = {contamination}\")\n",
    "\n",
    "        lof = LocalOutlierFactor(n_neighbors=n_neighbors, contamination=contamination)\n",
    "        outlier_mask = lof.fit_predict(X_train) == 1\n",
    "        X_train = X_train[outlier_mask]\n",
    "        y_train = y_train[outlier_mask]\n",
    "\n",
    "        if apply_to_test_data:\n",
    "            outlier_mask_test = lof.fit_predict(X_test) == 1\n",
    "            X_test = X_test[outlier_mask_test]\n",
    "            y_test = y_test[outlier_mask_test]\n",
    "\n",
    "    else:\n",
    "        print(\"No outlier removal method chosen.\")\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-10T01:44:05.717223300Z",
     "start_time": "2023-09-10T01:44:05.460623900Z"
    }
   },
   "id": "ad2b6e564ddc5872"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# CHECK MULTICOLLINEARITY"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "edcb08003e76be5d"
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [],
   "source": [
    "# CHECK MULTICOLLINEARITY\n",
    "\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "def check_multicol(X_train, X_test, y_train, y_test):\n",
    "    \"\"\"\n",
    "    Purpose:\n",
    "    Check for multicollinearity in the training dataset using correlation and Variance Inflation Factor (VIF).\n",
    "\n",
    "    Parameters:\n",
    "        - X_train, X_test (pd.DataFrame): Training and testing feature sets\n",
    "        - y_train, y_test (pd.Series or array-like): Training and testing labels\n",
    "\n",
    "    Returns:\n",
    "        None (prints out the results)\n",
    "\n",
    "    Note:\n",
    "    The function prints out the correlation and VIF results based on predefined thresholds.\n",
    "    - High Correlation: > 0.8\n",
    "    - High VIF: > 10\n",
    "\n",
    "    The function also populates and prints a results dictionary to summarize the findings.\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"\\n[CHECK MULTICOLLINEARITY]\\n\")\n",
    "\n",
    "    # Thresholds\n",
    "    corr_threshold = 0.8\n",
    "    vif_threshold = 10\n",
    "    print(f\"Thresholds used for analysis:\")\n",
    "    print(f\"High Correlation: > {corr_threshold}\")\n",
    "    print(f\"High VIF: > {vif_threshold}\\n\")\n",
    "    print(f\"Results:\")\n",
    "\n",
    "    # Prepare the results dictionary\n",
    "    results = {}\n",
    "\n",
    "    # 1. Correlation Analysis\n",
    "    correlation_matrix = X_train.corr()\n",
    "    high_correlation_pairs = np.where(np.abs(correlation_matrix) > corr_threshold)\n",
    "    high_correlation_pairs = [(X_train.columns[x], X_train.columns[y]) for x, y in zip(*high_correlation_pairs) if x != y and x < y]\n",
    "    for pair in high_correlation_pairs:\n",
    "        results[pair] = \"High Correlation\"\n",
    "\n",
    "    # 2. VIF\n",
    "    vif_data = pd.DataFrame()\n",
    "    vif_data[\"Feature\"] = X_train.columns\n",
    "    vif_data[\"VIF\"] = [variance_inflation_factor(X_train.values, i) for i in range(X_train.shape[1])]\n",
    "    high_vif_features = vif_data[vif_data[\"VIF\"] > vif_threshold][\"Feature\"].tolist()\n",
    "    for feature in high_vif_features:\n",
    "        for pair in high_correlation_pairs:\n",
    "            if feature in pair:\n",
    "                if pair in results:\n",
    "                    results[pair] += f\", High VIF for {feature} column\"\n",
    "                else:\n",
    "                    results[pair] = f\"High VIF for {feature} column\"\n",
    "\n",
    "    # Print results\n",
    "    if not results:\n",
    "        print(\"No issues detected.\")\n",
    "    else:\n",
    "        for key, value in results.items():\n",
    "            print(f\"{key}: {value}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-10T01:44:05.717223300Z",
     "start_time": "2023-09-10T01:44:05.475114500Z"
    }
   },
   "id": "231dc97c61e47e03"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# SCALING"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "166a9b5eb46e029e"
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [],
   "source": [
    "# SCALING\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "def scale_data(X_train, X_test, scaler_type='standard', scaler_exclude_columns=None):\n",
    "    \"\"\"\n",
    "    Purpose:\n",
    "    Scale the features in the training and testing datasets.\n",
    "\n",
    "    Parameters:\n",
    "        - X_train, X_test (pd.DataFrame): Training and testing feature sets\n",
    "        - scaler_type (str): Type of scaler to use. Options are 'standard', 'minmax', or None.\n",
    "        - scaler_exclude_columns (list): List of columns to exclude from scaling\n",
    "\n",
    "    Returns:\n",
    "        - (pd.DataFrame, pd.DataFrame): Scaled X_train and X_test\n",
    "\n",
    "    Note:\n",
    "    The function prints out the scaling method chosen and the columns being skipped from scaling, if any.\n",
    "    \"\"\"\n",
    "    print(\"[SCALING]\\n\")\n",
    "\n",
    "    # Show chosen method here\n",
    "    print(\"Chosen Scaling Method: {}\".format(scaler_type))\n",
    "\n",
    "    # Check if scaling should be skipped\n",
    "    if scaler_type is None:\n",
    "        return X_train, X_test\n",
    "\n",
    "    if scaler_type == 'standard':\n",
    "        scaler = StandardScaler()\n",
    "    elif scaler_type == 'minmax':\n",
    "        scaler = MinMaxScaler()\n",
    "    else:\n",
    "        raise ValueError(\"Invalid scaler_type. Use 'standard', 'minmax', or 'None'.\")\n",
    "\n",
    "    if scaler_exclude_columns:\n",
    "        # Scale only the columns not in scaler_exclude_columns\n",
    "        scale_columns = [col for col in X_train.columns if col not in scaler_exclude_columns]\n",
    "        X_train_scaled = X_train.copy()\n",
    "        X_test_scaled = X_test.copy()\n",
    "        X_train_scaled[scale_columns] = scaler.fit_transform(X_train[scale_columns])\n",
    "        X_test_scaled[scale_columns] = scaler.transform(X_test[scale_columns])\n",
    "\n",
    "        # Print the columns being skipped from scaling\n",
    "        print(\"Columns being skipped from scaling: {}\".format(scaler_exclude_columns))\n",
    "    else:\n",
    "        # Scale all columns\n",
    "        X_train_scaled = pd.DataFrame(scaler.fit_transform(X_train), columns=X_train.columns)\n",
    "        X_test_scaled = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns)\n",
    "\n",
    "    return X_train_scaled, X_test_scaled"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-10T01:44:05.718232700Z",
     "start_time": "2023-09-10T01:44:05.486947700Z"
    }
   },
   "id": "ae72ad4b5f89b36f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# TSNE PREVIEW"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bf4882b64c0eb7b8"
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [],
   "source": [
    "# TSNE PREVIEW\n",
    "\n",
    "import plotly.express as px\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "def tsne_preview(X_train, X_test, y_train, y_test, n_components=3, random_state=42):\n",
    "    \"\"\"\n",
    "    Purpose:\n",
    "    Create a t-SNE preview of the training and testing datasets.\n",
    "\n",
    "    Parameters:\n",
    "        - X_train, X_test (pd.DataFrame): Training and testing feature sets\n",
    "        - y_train, y_test (pd.Series or array-like): Training and testing labels\n",
    "        - n_components (int): Number of components for t-SNE\n",
    "        - random_state (int): Random state for reproducibility\n",
    "\n",
    "    Returns:\n",
    "        None (shows plotly figures)\n",
    "\n",
    "    Note:\n",
    "    The function generates 3D scatter plots for both the training and testing datasets.\n",
    "    \"\"\"\n",
    "    tsne = TSNE(n_components=n_components, random_state=random_state)\n",
    "\n",
    "    train_tsne_features = tsne.fit_transform(X_train)\n",
    "    train_tsne_df = pd.DataFrame(train_tsne_features, columns=[f'TSNE{i}' for i in range(1, n_components+1)])\n",
    "    train_tsne_df['target'] = y_train\n",
    "\n",
    "    test_tsne_features = tsne.fit_transform(X_test)\n",
    "    test_tsne_df = pd.DataFrame(test_tsne_features, columns=[f'TSNE{i}' for i in range(1, n_components+1)])\n",
    "    test_tsne_df['target'] = y_test\n",
    "\n",
    "    train_fig = px.scatter_3d(train_tsne_df, x='TSNE1', y='TSNE2', z='TSNE3', color='target')\n",
    "    test_fig = px.scatter_3d(test_tsne_df, x='TSNE1', y='TSNE2', z='TSNE3', color='target')\n",
    "\n",
    "    print(\"[T-SNE PREVIEW TRAIN SET]\")\n",
    "    train_fig.show()\n",
    "    print(\"[T-SNE PREVIEW TEST SET]\")\n",
    "    test_fig.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-10T01:44:05.718232700Z",
     "start_time": "2023-09-10T01:44:05.504885Z"
    }
   },
   "id": "a8e4ec41c46322e7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# UMAP PREVIEW"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f58cc148903f7644"
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [],
   "source": [
    "# UMAP PREVIEW\n",
    "\n",
    "import plotly.express as px\n",
    "from umap.umap_ import UMAP\n",
    "\n",
    "def umap_preview(X_train, X_test, y_train, y_test, n_components=3, random_state=42):\n",
    "    \"\"\"\n",
    "    Purpose:\n",
    "    Create a UMAP preview of the training and testing datasets.\n",
    "\n",
    "    Parameters:\n",
    "        - X_train, X_test (pd.DataFrame): Training and testing feature sets\n",
    "        - y_train, y_test (pd.Series or array-like): Training and testing labels\n",
    "        - n_components (int): Number of components for UMAP\n",
    "        - random_state (int): Random state for reproducibility\n",
    "\n",
    "    Returns:\n",
    "        None (shows plotly figures)\n",
    "\n",
    "    Note:\n",
    "    The function generates 3D scatter plots for both the training and testing datasets.\n",
    "    \"\"\"\n",
    "    umap_model = UMAP(n_components=n_components, random_state=random_state)\n",
    "\n",
    "    train_umap_features = umap_model.fit_transform(X_train)\n",
    "    train_umap_df = pd.DataFrame(train_umap_features, columns=[f'UMAP{i}' for i in range(1, n_components+1)])\n",
    "    train_umap_df['target'] = y_train\n",
    "\n",
    "    test_umap_features = umap_model.fit_transform(X_test)\n",
    "    test_umap_df = pd.DataFrame(test_umap_features, columns=[f'UMAP{i}' for i in range(1, n_components+1)])\n",
    "    test_umap_df['target'] = y_test\n",
    "\n",
    "    train_fig = px.scatter_3d(train_umap_df, x='UMAP1', y='UMAP2', z='UMAP3', color='target')\n",
    "    test_fig = px.scatter_3d(test_umap_df, x='UMAP1', y='UMAP2', z='UMAP3', color='target')\n",
    "\n",
    "    print(\"[UMAP PREVIEW TRAIN SET]\")\n",
    "    train_fig.show()\n",
    "    print(\"[UMAP PREVIEW TEST SET]\")\n",
    "    test_fig.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-10T01:44:05.718232700Z",
     "start_time": "2023-09-10T01:44:05.519104600Z"
    }
   },
   "id": "3256f20794e4bebf"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# PCA PREVIEW"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "76fbfd497af35976"
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [],
   "source": [
    "# PCA PREVIEW\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def pca_preview(X_train, X_test):\n",
    "    \"\"\"\n",
    "    Purpose:\n",
    "    Preview the explained and cumulative variance of features in the training and test datasets using PCA.\n",
    "\n",
    "    Parameters:\n",
    "        - X_train, X_test (pd.DataFrame): Training and testing feature sets\n",
    "\n",
    "    Returns:\n",
    "        None (shows plots and prints explained variance)\n",
    "\n",
    "    Note:\n",
    "    This function generates variance plots and prints out the optimal number of components for PCA based on the Kaiser criterion.\n",
    "    Kaiser criterion is just a recommended starting point, always visualize and experiment.\n",
    "    \"\"\"\n",
    "    print(\"[PCA PREVIEW]\\n\")\n",
    "    for data_name, data in zip(['Train', 'Test'], [X_train, X_test]):\n",
    "        print(f\"\\n{data_name} Data:\")\n",
    "\n",
    "        features = data\n",
    "\n",
    "        # Perform PCA\n",
    "        pca = PCA()\n",
    "        pca.fit(features)\n",
    "        explained_variance = pca.explained_variance_ratio_\n",
    "        cumulative_variance = np.cumsum(explained_variance)\n",
    "\n",
    "        # Determine optimal components using Kaiser criterion\n",
    "        optimal_components = np.sum(explained_variance > 1)  # Example threshold\n",
    "\n",
    "        # Plot explained variance and cumulative variance\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.plot(explained_variance, marker='o', label='Explained Variance', color='lightgreen')\n",
    "        plt.plot(cumulative_variance, marker='o', linestyle='--', label='Cumulative Variance', color='darkgreen')\n",
    "        plt.xlabel('Component')\n",
    "        plt.ylabel('Variance')\n",
    "        plt.title(f'{data_name} Data: Explained and Cumulative Variance per Component')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "        # Display Kaiser criterion result\n",
    "        print(f\"\\n[OPTIMAL PCA COMPONENTS BY KAISER CRITERION ({data_name} Data)]:\\n {optimal_components}\")\n",
    "        if optimal_components == 0:\n",
    "            print(\"According to Kaiser criterion, PCA might not be necessary.\")\n",
    "\n",
    "        # Display explained variance per component\n",
    "        print(f\"\\n[EXPLAINED VARIANCE PER COMPONENT ({data_name} Data)]:\")\n",
    "        for idx, variance in enumerate(explained_variance, start=1):\n",
    "            print(f\"Component {idx}: {variance:.4f}\")\n",
    "\n",
    "        # Display cumulative variance per component\n",
    "        print(f\"\\n[CUMULATIVE VARIANCE PER COMPONENT ({data_name} Data)]:\")\n",
    "        for idx, variance in enumerate(cumulative_variance, start=1):\n",
    "            print(f\"Components {idx}: {variance:.4f}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-10T01:44:05.718232700Z",
     "start_time": "2023-09-10T01:44:05.535147600Z"
    }
   },
   "id": "e6676876401ca56f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# FEATURE EXTRACTION / DIMENSIONALITY REDUCTION"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dc97a8150fe3180d"
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [],
   "source": [
    "# FEATURE EXTRACTION / DIMENSIONALITY REDUCTION\n",
    "\n",
    "from sklearn.decomposition import PCA, FastICA, TruncatedSVD\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "def extract_features_dim_reduce(X_train, X_test, y_train, y_test, n_components=3, random_state=42, method=None):\n",
    "    \"\"\"\n",
    "    Purpose:\n",
    "    Perform feature extraction or dimensionality reduction on the feature sets.\n",
    "\n",
    "    Parameters:\n",
    "        - X_train, X_test (pd.DataFrame): Training and testing feature sets\n",
    "        - y_train, y_test (pd.Series or array-like): Training and testing labels\n",
    "        - n_components (int): Number of components for the chosen method\n",
    "        - random_state (int): Random state for reproducibility\n",
    "        - method (str): Feature extraction or reduction method ('pca', 'ica', 'svd', 'lda', or None)\n",
    "\n",
    "    Returns:\n",
    "        - (pd.DataFrame, pd.DataFrame, pd.Series, pd.Series): Transformed X_train, X_test, y_train, and y_test\n",
    "    \"\"\"\n",
    "    print(f\"[FEATURE EXTRACTION / DIMENSIONALITY REDUCTION METHOD CHOSEN]\\n{method}\")\n",
    "\n",
    "    if method == None:\n",
    "        return X_train, X_test, y_train, y_test\n",
    "    elif method == 'pca':\n",
    "        reducer = PCA(n_components=n_components)\n",
    "        X_train = reducer.fit_transform(X_train)\n",
    "        X_test = reducer.transform(X_test)\n",
    "    elif method == 'ica':\n",
    "        reducer = FastICA(n_components=n_components, random_state=random_state)\n",
    "        X_train = reducer.fit_transform(X_train)\n",
    "        X_test = reducer.transform(X_test)\n",
    "    elif method == 'svd':\n",
    "        reducer = TruncatedSVD(n_components=n_components, random_state=random_state)\n",
    "        X_train = reducer.fit_transform(X_train)\n",
    "        X_test = reducer.transform(X_test)\n",
    "    elif method == 'lda':\n",
    "        reducer = LinearDiscriminantAnalysis(n_components=n_components)\n",
    "        X_train = reducer.fit_transform(X_train, y_train)\n",
    "        X_test = reducer.transform(X_test)\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid method '{method}'. Please choose one of the following: 'pca', 'ica', 'svd', 'lda', 'None'.\")\n",
    "\n",
    "    # Convert the transformed data to a pandas DataFrame and assign column names\n",
    "    if method != None:\n",
    "        column_names = [f'{method.upper()}{i}' for i in range(1, n_components+1)]\n",
    "        X_train = pd.DataFrame(X_train, columns=column_names)\n",
    "        X_test = pd.DataFrame(X_test, columns=column_names)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-10T01:44:05.718232700Z",
     "start_time": "2023-09-10T01:44:05.552649100Z"
    }
   },
   "id": "77925d6e7d2ed360"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# OVERSAMPLING & UNDERSAMPLING"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cbffe51fd3b60b8a"
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [],
   "source": [
    "# OVERSAMPLING & UNDERSAMPLING\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.combine import SMOTEENN, SMOTETomek\n",
    "\n",
    "def balance_classes(X_train, y_train, method='oversample', random_state=42, k_neighbors=5):\n",
    "    \"\"\"\n",
    "    Purpose:\n",
    "    Balance class distribution in the training set via oversampling, undersampling, or combined methods.\n",
    "\n",
    "    Parameters:\n",
    "        - X_train (pd.DataFrame): Training feature set\n",
    "        - y_train (pd.Series or array-like): Training labels\n",
    "        - method (str): Method to balance classes ('oversample', 'undersample', 'mixedenn', 'mixedtomek')\n",
    "        - random_state (int): Random state for reproducibility\n",
    "        - k_neighbors (int): Number of nearest neighbors for SMOTE\n",
    "\n",
    "    Returns:\n",
    "        - (pd.DataFrame, pd.Series): Resampled X_train and y_train\n",
    "\n",
    "    Note:\n",
    "    The function prints out the new class distribution in the training set.\n",
    "    \"\"\"\n",
    "    if method == 'oversample':\n",
    "        smote = SMOTE(random_state=random_state, k_neighbors=k_neighbors)\n",
    "        X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "    elif method == 'undersample':\n",
    "        rus = RandomUnderSampler(random_state=random_state)\n",
    "        X_train, y_train = rus.fit_resample(X_train, y_train)\n",
    "    elif method == 'mixedenn':\n",
    "        smeenn = SMOTEENN(random_state=random_state, smote=SMOTE(k_neighbors=k_neighbors))\n",
    "        X_train, y_train = smeenn.fit_resample(X_train, y_train)\n",
    "    elif method == 'mixedtomek':\n",
    "        smtomek = SMOTETomek(random_state=random_state, smote=SMOTE(k_neighbors=k_neighbors))\n",
    "        X_train, y_train = smtomek.fit_resample(X_train, y_train)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid method. Use 'oversample', 'undersample', 'mixedenn', or 'mixedtomek'.\")\n",
    "\n",
    "    print('Training Set Class Balance: \\n', y_train.value_counts())\n",
    "\n",
    "    return X_train, y_train"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-10T01:44:05.720627400Z",
     "start_time": "2023-09-10T01:44:05.564465300Z"
    }
   },
   "id": "2d1ffbccea7053fc"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# FEATURE SELECTION"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b91e76aedf3b07cb"
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [],
   "source": [
    "# FEATURE SELECTION\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.base import clone\n",
    "from mlxtend.feature_selection import ExhaustiveFeatureSelector\n",
    "\n",
    "def select_features_rfecv(X_train, X_test, y_train, y_test, chosen_rfecv_base_model, step_value=1, minimum_features_to_keep=5, cv=5):\n",
    "    \"\"\"\n",
    "    Purpose:\n",
    "    Perform feature selection using Recursive Feature Elimination with Cross-Validation (RFECV).\n",
    "\n",
    "    Parameters:\n",
    "        - X_train, X_test (pd.DataFrame): Training and testing feature sets\n",
    "        - y_train, y_test (pd.Series or array-like): Training and testing labels\n",
    "        - chosen_rfecv_base_model (sklearn estimator): The base model to use in RFECV\n",
    "        - step_value (int): Number of features to remove at each iteration\n",
    "        - minimum_features_to_keep (int): Minimum number of features to keep\n",
    "        - cv (int): Number of folds in cross-validation\n",
    "\n",
    "    Returns:\n",
    "        - (pd.DataFrame, pd.DataFrame, pd.Series, pd.Series): Transformed X_train, X_test, y_train, and y_test\n",
    "    \"\"\"\n",
    "    # Use RFECV to determine the most optimal features to keep\n",
    "    selector = RFECV(estimator=chosen_rfecv_base_model,\n",
    "                     step=step_value,\n",
    "                     min_features_to_select=minimum_features_to_keep,\n",
    "                     cv=cv)\n",
    "    selector.fit(X_train, y_train)\n",
    "\n",
    "    # Get the list of selected features\n",
    "    selected_features = X_train.columns[selector.support_]\n",
    "\n",
    "    # Get the features to drop\n",
    "    dropped_features = [feature for feature in X_train.columns if feature not in selected_features]\n",
    "\n",
    "    # Modify the train and test data accordingly\n",
    "    X_train = X_train[selected_features]\n",
    "    X_test = X_test[selected_features]\n",
    "\n",
    "    # Show the dropped features\n",
    "    print(\"[RFECV] Dropped features:\", dropped_features)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def select_features_permutation(X_train, X_test, y_train, y_test, permutation_chosen_model, n_features_to_keep=5, cv=5):\n",
    "    \"\"\"\n",
    "    Purpose:\n",
    "    Perform feature selection using Permutation Importance with cross-validation.\n",
    "\n",
    "    Parameters:\n",
    "        - X_train, X_test (pd.DataFrame): Training and testing feature sets\n",
    "        - y_train, y_test (pd.Series or array-like): Training and testing labels\n",
    "        - permutation_chosen_model (sklearn estimator): The model to use for calculating permutation importance\n",
    "        - n_features_to_keep (int): Number of top features to keep\n",
    "        - cv (int): Number of folds in cross-validation\n",
    "\n",
    "    Returns:\n",
    "        - (pd.DataFrame, pd.DataFrame, pd.Series, pd.Series): Transformed X_train, X_test, y_train, and y_test\n",
    "    \"\"\"\n",
    "    # Initialize an array to store permutation importances\n",
    "    perm_importances = np.zeros(X_train.shape[1])\n",
    "\n",
    "    # Perform cross-validation\n",
    "    kf = KFold(n_splits=cv, shuffle=True, random_state=42)\n",
    "\n",
    "    for train_index, val_index in kf.split(X_train):\n",
    "        X_train_cv, X_val_cv = X_train.iloc[train_index], X_train.iloc[val_index]\n",
    "        y_train_cv, y_val_cv = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "\n",
    "        # Train the model on the CV training set\n",
    "        permutation_chosen_model.fit(X_train_cv, y_train_cv)\n",
    "\n",
    "        # Calculate feature importances using permutation importance on the CV validation set\n",
    "        perm_importance = permutation_importance(permutation_chosen_model, X_val_cv, y_val_cv, n_repeats=30)\n",
    "\n",
    "        # Accumulate feature importances\n",
    "        perm_importances += perm_importance.importances_mean\n",
    "\n",
    "    # Average the feature importances over all CV folds\n",
    "    perm_importances /= cv\n",
    "\n",
    "    # Get the indices of the features sorted by importance\n",
    "    sorted_idx = perm_importances.argsort()[::-1]\n",
    "\n",
    "    # Get the list of selected features\n",
    "    selected_features = X_train.columns[sorted_idx][:n_features_to_keep]\n",
    "\n",
    "    # Modify the train and test data accordingly\n",
    "    X_train = X_train[selected_features]\n",
    "    X_test = X_test[selected_features]\n",
    "\n",
    "    # Show the dropped features\n",
    "    dropped_features = [feature for feature in X_train.columns if feature not in selected_features]\n",
    "    print(\"[PERMUTATION CV] Dropped features:\", dropped_features)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def select_features_basic_filter(X_train, X_test, tolerance=0.01):\n",
    "    \"\"\"\n",
    "    Purpose:\n",
    "    Performs a basic filter based feature selection by removing constant, quasi-constant, and duplicate features.\n",
    "\n",
    "    Parameters:\n",
    "        - X_train, X_test (pd.DataFrame): Training and testing feature sets\n",
    "        - tolerance (float): Variance threshold for determining constant and quasi-constant features\n",
    "\n",
    "    Returns:\n",
    "        - (pd.DataFrame, pd.DataFrame): Transformed X_train and X_test\n",
    "    \"\"\"\n",
    "    # Drop constant and quasi-constant features from X_train and get the remaining columns\n",
    "    constant_filter_train = X_train.var() > tolerance\n",
    "    X_train_filtered = X_train.loc[:, constant_filter_train]\n",
    "\n",
    "    # Apply the same filter to X_test\n",
    "    X_test_filtered = X_test.loc[:, constant_filter_train]\n",
    "\n",
    "    # Drop duplicated features from X_train and get the remaining columns\n",
    "    X_train_deduplicated = X_train_filtered.T.drop_duplicates().T\n",
    "    remaining_columns = X_train_deduplicated.columns\n",
    "    X_test_deduplicated = X_test_filtered[remaining_columns]\n",
    "\n",
    "    # Find the dropped features\n",
    "    dropped_features = set(X_train.columns) - set(remaining_columns)\n",
    "\n",
    "    # Show the dropped features\n",
    "    print(\"[BASIC FILTER] Dropped features:\", dropped_features)\n",
    "\n",
    "    return X_train_deduplicated, X_test_deduplicated\n",
    "\n",
    "def select_features_sequential(estimator, X_train, X_test, y_train, y_test,\n",
    "                               forward=False, cv=5,\n",
    "                               n_features_to_select='auto', tol=None, scoring='accuracy'):\n",
    "    \"\"\"\n",
    "    Purpose:\n",
    "    Perform feature selection using SequentialFeatureSelector from scikit-learn with cross-validation.\n",
    "    Supports both forward and backward selection methods\n",
    "\n",
    "    Parameters:\n",
    "        - estimator (sklearn estimator): The base model to use for feature selection.\n",
    "        - X_train, X_test (pd.DataFrame): Training and testing feature sets.\n",
    "        - y_train, y_test (pd.Series or array-like): Training and testing labels.\n",
    "        - forward (bool): Whether to perform forward selection. Default is False for backward selection.\n",
    "        - cv (int): Number of folds for cross-validation. Default is 5.\n",
    "        - n_features_to_select (int or 'auto'): Number of features to select. Default is 'auto'.\n",
    "        - tol (float or None): Tolerance for optimization. Default is None.\n",
    "        - scoring (str): Scoring metric used for feature selection. Default is 'accuracy'.\n",
    "\n",
    "    Returns:\n",
    "        - (pd.DataFrame, pd.DataFrame): Transformed X_train and X_test with irrelevant features removed.\n",
    "    \"\"\"\n",
    "\n",
    "    # Get feature names from DataFrame\n",
    "    feature_names = X_train.columns.tolist()\n",
    "\n",
    "    # Initialize SequentialFeatureSelector\n",
    "    sfs = SequentialFeatureSelector(estimator,\n",
    "                                    direction='forward' if forward else 'backward',\n",
    "                                    n_features_to_select=n_features_to_select,\n",
    "                                    tol=tol,\n",
    "                                    scoring=scoring,\n",
    "                                    cv=cv)\n",
    "\n",
    "    # Fit the model\n",
    "    sfs.fit(X_train, y_train)\n",
    "\n",
    "    # Identify and store dropped features\n",
    "    dropped_features = np.array(feature_names)[~sfs.get_support()]\n",
    "    print(\"[SEQUENTIAL FEATURE SELECTOR WITH CV] Dropped features:\", dropped_features)\n",
    "\n",
    "    # Transform data\n",
    "    X_train_transformed = X_train.loc[:, sfs.get_support()]\n",
    "    X_test_transformed = X_test.loc[:, sfs.get_support()]\n",
    "\n",
    "    return X_train_transformed, X_test_transformed\n",
    "\n",
    "def select_features_exhaustive(estimator, X_train, X_test, y_train, y_test,\n",
    "                               cv=5, min_features=5, scoring='accuracy'):\n",
    "    \"\"\"\n",
    "    Purpose:\n",
    "    Perform feature selection using the Exhaustive Feature Selector from mlxtend with cross-validation.\n",
    "\n",
    "    Parameters:\n",
    "        - estimator (sklearn estimator): The base model to use for feature selection\n",
    "        - X_train, X_test (pd.DataFrame or array-like): Training and testing feature sets\n",
    "        - y_train, y_test (pd.Series or array-like): Training and testing labels\n",
    "        - cv (int): Number of folds in cross-validation\n",
    "        - min_features (int): Minimum number of features to consider for selection\n",
    "        - scoring (str): Scoring metric used for feature selection\n",
    "\n",
    "    Returns:\n",
    "        - (pd.DataFrame or array-like, pd.DataFrame or array-like): Transformed X_train and X_test with best features selected\n",
    "    \"\"\"\n",
    "\n",
    "    # Get feature names if X_train is a DataFrame\n",
    "    if hasattr(X_train, 'columns'):\n",
    "        original_feature_names = X_train.columns.tolist()\n",
    "    else:\n",
    "        original_feature_names = [str(i) for i in range(X_train.shape[1])]\n",
    "\n",
    "    # Initialize Exhaustive Feature Selector\n",
    "    efs = ExhaustiveFeatureSelector(estimator,\n",
    "                                    min_features=min_features,\n",
    "                                    max_features=X_train.shape[1],\n",
    "                                    scoring=scoring,\n",
    "                                    cv=cv)\n",
    "\n",
    "    # Fit the selector to the data\n",
    "    efs = efs.fit(X_train, y_train)\n",
    "\n",
    "    # Get best feature indices and names\n",
    "    best_feature_indices = np.array(efs.best_idx_)\n",
    "    best_feature_names = np.array(original_feature_names)[best_feature_indices]\n",
    "\n",
    "    # Identify and print the dropped features\n",
    "    dropped_features = [feature for feature in original_feature_names if feature not in best_feature_names]\n",
    "    print(\"\\n\\n[EXHAUSTIVE FEATURE SELECTOR] Dropped features:\", dropped_features)\n",
    "\n",
    "    # Transform X_train and X_test based on best features\n",
    "    if hasattr(X_train, 'loc'):\n",
    "        X_train_transformed = X_train.loc[:, best_feature_names]\n",
    "        X_test_transformed = X_test.loc[:, best_feature_names]\n",
    "    else:\n",
    "        X_train_transformed = X_train[:, best_feature_indices]\n",
    "        X_test_transformed = X_test[:, best_feature_indices]\n",
    "\n",
    "    # Return transformed data\n",
    "    return X_train_transformed, X_test_transformed"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-10T01:44:05.720627400Z",
     "start_time": "2023-09-10T01:44:05.589279700Z"
    }
   },
   "id": "1bcb0da17bea01a4"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# MODEL EVALUATION (BINARY CLASSIFICATION)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8e10f3b99a472782"
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [],
   "source": [
    "# MODEL EVALUATION (BINARY CLASSIFICATION)\n",
    "\n",
    "from sklearn.metrics import classification_report, roc_auc_score, roc_curve, auc\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "\n",
    "def evaluate_binary_model(model, model_name, X_train, X_test, y_train, y_test, stratify=True):\n",
    "    \"\"\"\n",
    "    Evaluate a binary classification model.\n",
    "\n",
    "    Parameters:\n",
    "        model : The classification model\n",
    "        model_name : Name of the model (for printing)\n",
    "        X_train, y_train : Training data\n",
    "        X_test, y_test : Test data\n",
    "        stratify : Whether to use Stratified K-Fold (default True)\n",
    "\n",
    "    Returns:\n",
    "        None (prints and plots evaluation metrics)\n",
    "    \"\"\"\n",
    "    # Choose the appropriate KFold method based on stratify argument\n",
    "    if stratify:\n",
    "        cv_method = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    else:\n",
    "        cv_method = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    # Print mean 5-fold cross validation score\n",
    "    cv_score = np.mean(cross_val_score(model, X_train, y_train, cv=cv_method, scoring='accuracy', verbose=0)) * 100\n",
    "    print('[{}] Training Mean 5-Fold CV Score: {:.2f}%'.format(model_name, cv_score))\n",
    "\n",
    "    # Print test set accuracy score\n",
    "    test_accuracy = model.score(X_test, y_test) * 100\n",
    "    print('[{}] Test Set Accuracy Score: {:.2f}%'.format(model_name, test_accuracy))\n",
    "\n",
    "    # Print classification report\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(\"[{}] Classification Report:\\n\".format(model_name), classification_report(y_test, y_pred))\n",
    "\n",
    "    # Plot ROC AUC curve\n",
    "    y_prob = model.predict_proba(X_test)[:, 1]\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_prob)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(fpr, tpr, label='{} (AUC = {:.2f})'.format(model_name, roc_auc))\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC AUC Curve')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-10T01:44:05.837819700Z",
     "start_time": "2023-09-10T01:44:05.598243700Z"
    }
   },
   "id": "4652d4532467d01f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# MODEL EVALUATION (MULTI CLASS CLASSIFICATION)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5848a50050a341c5"
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [],
   "source": [
    "# MODEL EVALUATION (MULTI CLASS CLASSIFICATION)\n",
    "\n",
    "from sklearn.metrics import classification_report, roc_auc_score, roc_curve, auc\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "def evaluate_multiclass_model(model, model_name, X_train, X_test, y_train, y_test, stratify=True):\n",
    "    \"\"\"\n",
    "    Evaluate a multiclass classification model.\n",
    "\n",
    "    Parameters:\n",
    "        model : The classification model\n",
    "        model_name : Name of the model (for printing)\n",
    "        X_train, y_train : Training data\n",
    "        X_test, y_test : Test data\n",
    "        stratify : Whether to use Stratified K Fold (default is True)\n",
    "\n",
    "    Returns:\n",
    "        None (prints and plots evaluation metrics)\n",
    "    \"\"\"\n",
    "\n",
    "    # Create a KFold or StratifiedKFold instance based on the 'stratify' flag\n",
    "    if stratify:\n",
    "        cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    else:\n",
    "        cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    # Print mean 5-fold cross-validation score\n",
    "    cv_score = np.mean(cross_val_score(model, X_train, y_train, cv=cv, scoring='accuracy', verbose=0)) * 100\n",
    "    print('[{}] Training Mean 5-Fold CV Score: {:.2f}%'.format(model_name, cv_score))\n",
    "\n",
    "    # Print test set accuracy score\n",
    "    test_accuracy = model.score(X_test, y_test) * 100\n",
    "    print('[{}] Test Set Accuracy Score: {:.2f}%'.format(model_name, test_accuracy))\n",
    "\n",
    "    # Print classification report\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(\"[{}] Classification Report:\\n\".format(model_name), classification_report(y_test, y_pred))\n",
    "\n",
    "    # Plot ROC AUC curve for multi-class\n",
    "    n_classes = len(np.unique(y_test))\n",
    "    y_test_bin = label_binarize(y_test, classes=np.arange(n_classes))\n",
    "    y_prob = model.predict_proba(X_test)\n",
    "\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    for i in range(n_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_prob[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    for i in range(n_classes):\n",
    "        plt.plot(fpr[i], tpr[i], label='Class {} (AUC = {:.2f})'.format(i, roc_auc[i]))\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC AUC Curve')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-10T01:44:05.839814Z",
     "start_time": "2023-09-10T01:44:05.612471Z"
    }
   },
   "id": "5e90ef465fc1fba2"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# MODEL EVALUATION (REGRESSION)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a501c9662640d78b"
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [],
   "source": [
    "# MODEL EVALUATION (REGRESSION)\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "def evaluate_regression_model(model, model_name, X_train, X_test, y_train, y_test):\n",
    "    \"\"\"\n",
    "    Evaluate a regression model.\n",
    "\n",
    "    Parameters:\n",
    "        model : The regression model\n",
    "        model_name : Name of the model (for printing)\n",
    "        X_train, y_train : Training data\n",
    "        X_test, y_test : Test data\n",
    "\n",
    "    Returns:\n",
    "        None (prints evaluation metrics)\n",
    "    \"\"\"\n",
    "    # Print mean 5-fold cross-validation MSE score\n",
    "    cv_mse_score = np.mean(-cross_val_score(model, X_train, y_train, cv=5, scoring='neg_mean_squared_error', verbose=0))\n",
    "    print('\\n[{}] Training Mean 5-Fold CV MSE: {:.2f}'.format(model_name, cv_mse_score))\n",
    "\n",
    "    # Print mean 5-fold cross-validation MAE score\n",
    "    cv_mae_score = np.mean(-cross_val_score(model, X_train, y_train, cv=5, scoring='neg_mean_absolute_error', verbose=0))\n",
    "    print('[{}] Training Mean 5-Fold CV MAE: {:.2f}'.format(model_name, cv_mae_score))\n",
    "\n",
    "    # Print test set MSE score\n",
    "    test_mse = mean_squared_error(y_test, model.predict(X_test))\n",
    "    print('[{}] Test Set MSE: {:.2f}'.format(model_name, test_mse))\n",
    "\n",
    "    # Print test set MAE score\n",
    "    test_mae = mean_absolute_error(y_test, model.predict(X_test))\n",
    "    print('[{}] Test Set MAE: {:.2f}'.format(model_name, test_mae))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-10T01:44:05.839814Z",
     "start_time": "2023-09-10T01:44:05.626845100Z"
    }
   },
   "id": "350898aae53fa6ef"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# PLOT FEATURE IMPORTANCES"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4900a80be27692ea"
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [],
   "source": [
    "# PLOT FEATURE IMPORTANCES\n",
    "\n",
    "def plot_feature_importance(model, model_name, X_train):\n",
    "    \"\"\"\n",
    "    Plot the feature importances for a given model if available.\n",
    "\n",
    "    Parameters:\n",
    "        model : The trained model\n",
    "        model_name : Name of the model (for printing)\n",
    "        X_train : Training feature data\n",
    "\n",
    "    Returns:\n",
    "        None (displays a plot)\n",
    "    \"\"\"\n",
    "    # Check if the model has feature importances\n",
    "    if hasattr(model, 'feature_importances_'):\n",
    "        feat_importances = model.feature_importances_\n",
    "\n",
    "        # Plot the feature importances\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        sns.barplot(x=feat_importances, y=X_train.columns)\n",
    "        plt.title('{} Feature Importance Plot'.format(model_name))\n",
    "        plt.xlabel('{} Feature Importance'.format(model_name))\n",
    "        plt.ylabel('Features')\n",
    "        plt.show()\n",
    "    else:\n",
    "        # If the model doesn't have feature importances, print a note\n",
    "        print(\"\\n NOTE: Feature importances are not available for {}. \\n\".format(model_name))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-10T01:44:05.840815100Z",
     "start_time": "2023-09-10T01:44:05.646770400Z"
    }
   },
   "id": "e62bfcb917fdab7e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# SHOW SHAP VALUES"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "da0d0c5f6a47a301"
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [],
   "source": [
    "# SHOW SHAP VALUES\n",
    "\n",
    "import shap\n",
    "\n",
    "def plot_shap_values(model, model_name, X_train, multi_class=False):\n",
    "    \"\"\"\n",
    "    Plot the SHAP values for a given model if available.\n",
    "\n",
    "    Parameters:\n",
    "        model : The trained model\n",
    "        model_name : Name of the model (for printing)\n",
    "        X_train : Training feature data\n",
    "        multi_class : Whether the model is multi-class or not (default is False)\n",
    "\n",
    "    Returns:\n",
    "        None (displays a plot)\n",
    "    \"\"\"\n",
    "    # Check if the model is suitable for calculating shap values\n",
    "    if hasattr(model, 'feature_importances_'):\n",
    "        # Create an explainer object for the model\n",
    "        explainer = shap.TreeExplainer(model)\n",
    "\n",
    "        # Calculate the Shapley values for the model\n",
    "        shap_values = explainer.shap_values(X_train)\n",
    "\n",
    "        # If multi_class, take the mean of the shap values across the classes\n",
    "        if multi_class and isinstance(shap_values, list):\n",
    "            shap_values = np.mean(shap_values, axis=0)\n",
    "\n",
    "        # Plot the Shapley values for each feature\n",
    "        shap.summary_plot(shap_values, X_train, plot_type='bar', show=False)\n",
    "        plt.title('{} Shap Value Plot'.format(model_name))\n",
    "        plt.xlabel('Shapley Value')\n",
    "        plt.ylabel('Features')\n",
    "        plt.show()\n",
    "    else:\n",
    "        # If the model is not suitable for calculating shap values, print a note\n",
    "        print(\"\\n NOTE: Shap values are not available for {}. \\n\".format(model_name))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-10T01:44:05.840815100Z",
     "start_time": "2023-09-10T01:44:05.657804900Z"
    }
   },
   "id": "8a3bf54cb6bc12e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
